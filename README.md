# CML语音交互项目说明
## 项目概述
本项目旨在实现一个智能语音交互系统，能够实时录制用户的语音输入，将其转换为文本后发送给AI模型获取回复，并将回复转换为语音播放给用户，同时支持命令行和口语两种交流环境。

## 功能特点
- **实时语音检测与录制**：运用先进的语音活动检测（VAD）技术，能够敏锐地感知用户开始说话，并自动开始录音；当检测到一段时间的静音后，会自动停止录音，确保只录制有效语音内容，减少不必要的音频数据存储和处理。
- **精准音频转录**：借助`faster_whisper`模型，将录制的音频准确高效地转换为文本，为后续与AI模型的交互提供清晰准确的输入。
- **强大的AI对话能力**：基于OpenAI的`deepseek-chat`模型，能够理解用户的问题并生成高质量、逻辑清晰且富有针对性的回答，无论是知识问答、日常聊天还是复杂问题的讨论，都能为用户提供满意的回复。
- **逼真的语音合成与播放**：通过`edge-tts`技术，将AI模型生成的文本转换为自然流畅、清晰逼真的语音，让用户能够以最直观的方式接收信息，增强交互体验。

## 文件介绍
- **`cml_ai_talk.py`**：适用于口语交流环境，用户无需手动操作开始和停止录音，系统自动根据语音活动进行录制和停止，实现更加便捷自然的交互体验。
- **`cml_speech_ntemp_details.py`**：针对命令行交流环境，用户通过按下回车键开始录音，每次录音时长固定，操作简单直接，适合习惯命令行交互的用户。

## 运行方式
1. **安装依赖**：确保已经安装了`asyncio`、`edge-tts`、`signal`、`sys`、`openai`、`sounddevice`、`numpy`、`faster_whisper`、`fuzzywuzzy`、`io`、`soundfile`、`librosa`、`playsound`等依赖库。
2. **设置API密钥**：在代码中找到`API_KEY`和`BASE_URL`的定义位置，将其替换为自己的OpenAI API密钥和对应的基础URL，以便能够成功调用AI模型服务。
3. **运行程序**：在命令行中执行`python cml_ai_talk.py`（口语交流环境）或`python cml_speech_ntemp_details.py`（命令行交流环境），根据相应的交互提示进行操作即可开始与智能语音助手进行对话。

## 注意事项
- 由于项目中使用了特定的AI模型和语音技术，网络连接状况可能会影响AI响应速度和语音合成的流畅性，请确保网络稳定。
- 在录制音频时，尽量选择安静的环境，以提高语音识别的准确率。
- 当使用`Ctrl+C`退出程序时，程序会尝试进行优雅退出，但仍可能存在部分资源未完全释放的情况，如果遇到异常情况，可以尝试再次运行程序或者重启相关设备和服务。

